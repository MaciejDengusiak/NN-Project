{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f428154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import functional as F\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision.transforms.v2 as T  # PyTorch >= 2.0 preferred\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ffcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fae71",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "COCO_PATH = \"/path/to/COCO\"  # change this\n",
    "IMG_DIR_TRAIN = os.path.join(COCO_PATH, \"images/train2017\")\n",
    "IMG_DIR_VAL = os.path.join(COCO_PATH, \"images/val2017\")\n",
    "ANN_FILE_TRAIN = os.path.join(COCO_PATH, \"annotations/person_keypoints_train2017.json\")\n",
    "ANN_FILE_VAL = os.path.join(COCO_PATH, \"annotations/person_keypoints_val2017.json\")\n",
    "\n",
    "# Basic transform (you can expand this later)\n",
    "class ToTensorTransform:\n",
    "    def __call__(self, image, target):\n",
    "        return F.to_tensor(image), target\n",
    "\n",
    "# Custom dataset wrapper to use keypoints\n",
    "class CocoKeypointsDataset(CocoDetection):\n",
    "    def __init__(self, img_folder, ann_file, transforms=None):\n",
    "        super().__init__(img_folder, ann_file)\n",
    "        self.coco = COCO(ann_file)\n",
    "        self._transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super().__getitem__(idx)\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=self.ids[idx], iscrowd=None)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        # Filter for annotations with keypoints\n",
    "        anns = [ann for ann in anns if 'keypoints' in ann]\n",
    "        target = {\n",
    "            \"image_id\": self.ids[idx],\n",
    "            \"annotations\": anns\n",
    "        }\n",
    "        if self._transforms:\n",
    "            img, target = self._transforms(img, target)\n",
    "        return img, target\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = CocoKeypointsDataset(IMG_DIR_TRAIN, ANN_FILE_TRAIN, transforms=ToTensorTransform())\n",
    "val_dataset = CocoKeypointsDataset(IMG_DIR_VAL, ANN_FILE_VAL, transforms=ToTensorTransform())\n",
    "\n",
    "# Optional: split val set for a test set\n",
    "val_size = int(0.5 * len(val_dataset))\n",
    "test_size = len(val_dataset) - val_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949b8fa",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_KEYPOINTS = 17\n",
    "\n",
    "class KeypointModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, NUM_KEYPOINTS * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0413d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeypointModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d818929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, targets in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        keypoints = targets['keypoints'].reshape(imgs.size(0), -1).to(device)\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, keypoints)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ae4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    preds_list, gt_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            keypoints = targets['keypoints'].reshape(imgs.size(0), -1).to(device)\n",
    "            preds = model(imgs)\n",
    "\n",
    "            preds_list.append(preds.cpu())\n",
    "            gt_list.append(keypoints.cpu())\n",
    "    return preds_list, gt_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d80193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_prediction(img_tensor, keypoints, pred_keypoints=None):\n",
    "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    keypoints = keypoints.view(-1, 2).cpu().numpy()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(keypoints[:, 0], keypoints[:, 1], c='g', label='Ground Truth')\n",
    "    if pred_keypoints is not None:\n",
    "        pred_keypoints = pred_keypoints.view(-1, 2).cpu().numpy()\n",
    "        plt.scatter(pred_keypoints[:, 0], pred_keypoints[:, 1], c='r', marker='x', label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
